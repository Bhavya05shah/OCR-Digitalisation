{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpKlbZwRQHjFh6DJ2zTAEl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhavya05shah/OCR-Digitalisation/blob/main/Image_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhsxJwoNeRY2"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "image_file = \"OCRexp1.png\"\n",
        "img = cv2.imread(image_file)\n",
        "\n",
        "def display(image):\n",
        "    dpi = 80\n",
        "\n",
        "    height, width  = image.shape[:2]\n",
        "\n",
        "    # What size does the figure need to be in inches to fit the image?\n",
        "    figsize = width / float(dpi), height / float(dpi)\n",
        "\n",
        "    # Create a figure of the right size with one axes that takes up the full figure\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    ax = fig.add_axes([0, 0, 1, 1])\n",
        "\n",
        "    # Hide spines, ticks, etc.\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Display the image.\n",
        "    ax.imshow(image , cmap='gray')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# display(img)\n",
        "\n",
        "inverted_image = cv2.bitwise_not(img)\n",
        "# display(inverted_image)\n",
        "\n",
        "def grayscale(image):\n",
        "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "gray_image = grayscale(img)\n",
        "# display(gray_image)\n",
        "\n",
        "thresh, im_bw = cv2.threshold(gray_image, 210, 230, cv2.THRESH_BINARY)\n",
        "# display(im_bw)\n",
        "\n",
        "def noise_removal(image):\n",
        "    kernel = np.ones((1, 1), np.uint8)\n",
        "    image = cv2.dilate(image, kernel, iterations=1)\n",
        "    kernel = np.ones((1, 1), np.uint8)\n",
        "    image = cv2.erode(image, kernel, iterations=1)\n",
        "    image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
        "    image = cv2.medianBlur(image, 3)\n",
        "    return (image)\n",
        "\n",
        "no_noise = noise_removal(im_bw)\n",
        "\n",
        "def remove_borders(image):\n",
        "    contours, heiarchy = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cntsSorted = sorted(contours, key=lambda x:cv2.contourArea(x))\n",
        "    cnt = cntsSorted[-1]\n",
        "    x, y, w, h = cv2.boundingRect(cnt)\n",
        "    crop = image[y:y+h, x:x+w]\n",
        "    return (crop)\n",
        "\n",
        "no_borders = remove_borders(no_noise)"
      ]
    }
  ]
}